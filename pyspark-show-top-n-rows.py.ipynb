{"cells":[{"cell_type":"code","source":["import pyspark\nfrom pyspark.sql import SparkSession\n\nspark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()\n\nsimpleData = [(\"James\",34),(\"Ann\",34),\n    (\"Michael\",33),(\"Scott\",53),\n    (\"Robert\",37),(\"Chad\",27)\n  ]\n\ncolumns = [\"firstname\",\"age\",]\ndf = spark.createDataFrame(data = simpleData, schema = columns)\n\n\ndf.show()\n#Returns the first ``num`` rows as a :class:`list` of :class:`Row`.\n# Internally calls limit and collect\n#Action, Return Array[T]\nprint(df.take(2))\n\n#Returns the last ``num`` rows as a :class:`list` of :class:`Row`.\n#Running tail requires moving data into the application's driver process, and doing so with\n#a very large ``num`` can crash the driver process with OutOfMemoryError.\n#Return Array[T]\nprint(df.tail(2))\n\n\n\"\"\"Returns the first ``n`` rows.\n.. note:: This method should only be used if the resulting array is expected\n    to be small, as all the data is loaded into the driver's memory.\n:param n: int, default 1. Number of rows to return.\n:return: If n is greater than 1, return a list of :class:`Row`.\n    If n is 1, return a single Row.\"\"\"\n#Return Array[T]\nprint(df.head(2))\n\n\n#Returns the first row, same as df.head(1)\nprint(df.first())\n\n#Returns all the records as a list of :class:`Row`.\n#Action, Return Array[T]\nprint(df.collect())\n#\"Limits the result count to the number specified.\n#Returns a new Dataset by taking the first n rows.\npandasDF=df.limit(3).toPandas()\nprint(pandasDF)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"5d5075f0-2c33-4039-8059-b416daf20e5d","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+---------+---+\n|firstname|age|\n+---------+---+\n|    James| 34|\n|      Ann| 34|\n|  Michael| 33|\n|    Scott| 53|\n|   Robert| 37|\n|     Chad| 27|\n+---------+---+\n\n[Row(firstname='James', age=34), Row(firstname='Ann', age=34)]\n[Row(firstname='Robert', age=37), Row(firstname='Chad', age=27)]\n[Row(firstname='James', age=34), Row(firstname='Ann', age=34)]\nRow(firstname='James', age=34)\n[Row(firstname='James', age=34), Row(firstname='Ann', age=34), Row(firstname='Michael', age=33), Row(firstname='Scott', age=53), Row(firstname='Robert', age=37), Row(firstname='Chad', age=27)]\n  firstname  age\n0     James   34\n1       Ann   34\n2   Michael   33\n"]}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"pyspark-show-top-n-rows.py","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{}}},"nbformat":4,"nbformat_minor":0}
