{"cells":[{"cell_type":"code","source":["from pyspark.sql import SparkSession\nspark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()\ndata = [\"Project Gutenberg’s\",\n        \"Alice’s Adventures in Wonderland\",\n        \"Project Gutenberg’s\",\n        \"Adventures in Wonderland\",\n        \"Project Gutenberg’s\"]\nrdd=spark.sparkContext.parallelize(data)\n\nfor element in rdd.collect():\n    print(element)\n\n#Flatmap    \nrdd2=rdd.flatMap(lambda x: x.split(\" \"))\nfor element in rdd2.collect():\n    print(element)\n#map\nrdd3=rdd2.map(lambda x: (x,1))\nfor element in rdd3.collect():\n    print(element)\n#reduceByKey\nrdd4=rdd3.reduceByKey(lambda a,b: a+b)\nfor element in rdd4.collect():\n    print(element)\n#map\nrdd5 = rdd4.map(lambda x: (x[1],x[0])).sortByKey()\nfor element in rdd5.collect():\n    print(element)\n#filter\nrdd6 = rdd5.filter(lambda x : 'a' in x[1])\nfor element in rdd6.collect():\n    print(element)\n\nfrom pyspark.sql.functions import col,expr\ndata=[(\"2019-01-23\",1),(\"2019-06-24\",2),(\"2019-09-20\",3)]\nspark.createDataFrame(data).toDF(\"date\",\"increment\") \\\n    .select(col(\"date\"),col(\"increment\"), \\\n      expr(\"add_months(to_date(date,'yyyy-MM-dd'),cast(increment as int))\").alias(\"inc_date\")) \\\n    .show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"bf4ebfa0-4bf2-4680-92c5-2cf447ee6f60","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["Project Gutenberg’s\nAlice’s Adventures in Wonderland\nProject Gutenberg’s\nAdventures in Wonderland\nProject Gutenberg’s\nProject\nGutenberg’s\nAlice’s\nAdventures\nin\nWonderland\nProject\nGutenberg’s\nAdventures\nin\nWonderland\nProject\nGutenberg’s\n('Project', 1)\n('Gutenberg’s', 1)\n('Alice’s', 1)\n('Adventures', 1)\n('in', 1)\n('Wonderland', 1)\n('Project', 1)\n('Gutenberg’s', 1)\n('Adventures', 1)\n('in', 1)\n('Wonderland', 1)\n('Project', 1)\n('Gutenberg’s', 1)\n('Gutenberg’s', 3)\n('Adventures', 2)\n('Wonderland', 2)\n('Alice’s', 1)\n('in', 2)\n('Project', 3)\n(1, 'Alice’s')\n(2, 'Adventures')\n(2, 'Wonderland')\n(2, 'in')\n(3, 'Gutenberg’s')\n(3, 'Project')\n(2, 'Wonderland')\n+----------+---------+----------+\n|      date|increment|  inc_date|\n+----------+---------+----------+\n|2019-01-23|        1|2019-02-23|\n|2019-06-24|        2|2019-08-24|\n|2019-09-20|        3|2019-12-20|\n+----------+---------+----------+\n\n"]}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"pyspark-rdd-wordcount-2.py","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{}}},"nbformat":4,"nbformat_minor":0}
