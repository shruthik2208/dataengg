{"cells":[{"cell_type":"code","source":["from pyspark.sql import SparkSession\n\n# Create SparkSession\nspark = SparkSession.builder \\\n               .appName('SparkByExamples.com') \\\n               .getOrCreate()\n\nfrom pyspark.sql.functions import *\n\ndf=spark.createDataFrame([[\"02-03-2013\"],[\"05-06-2023\"]],[\"input\"])\ndf.select(col(\"input\"),to_date(col(\"input\"),\"MM-dd-yyyy\").alias(\"date\")) \\\n  .show()\n\n#SQL\nspark.sql(\"select to_date('02-03-2013','MM-dd-yyyy') date\").show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"ffc36936-ead4-42e0-b479-8aa24fdf2cbc","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+----------+----------+\n|     input|      date|\n+----------+----------+\n|02-03-2013|2013-02-03|\n|05-06-2023|2023-05-06|\n+----------+----------+\n\n+----------+\n|      date|\n+----------+\n|2013-02-03|\n+----------+\n\n"]}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"pyspark-string-date.py","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{}}},"nbformat":4,"nbformat_minor":0}
