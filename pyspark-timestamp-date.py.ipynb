{"cells":[{"cell_type":"code","source":["from pyspark.sql import SparkSession\n\n# Create SparkSession\nspark = SparkSession.builder \\\n          .appName('SparkByExamples.com') \\\n          .getOrCreate()\n\ndf=spark.createDataFrame(\n        data = [ (\"1\",\"2019-06-24 12:01:19.000\")],\n        schema=[\"id\",\"input_timestamp\"])\ndf.printSchema()\n\n\nfrom pyspark.sql.functions import *\n\n# Using Cast to convert Timestamp String to DateType\ndf.withColumn('date_type', col('input_timestamp').cast('date')) \\\n       .show(truncate=False)\n\n# Using Cast to convert TimestampType to DateType\ndf.withColumn('date_type', to_timestamp('input_timestamp').cast('date')) \\\n  .show(truncate=False)\n\ndf.select(to_date(lit('06-24-2019 12:01:19.000'),'MM-dd-yyyy HH:mm:ss.SSSS')) \\\n  .show()\n  \n#Timestamp String to DateType\ndf.withColumn(\"date_type\",to_date(\"input_timestamp\")) \\\n  .show(truncate=False)\n\n#Timestamp Type to DateType\ndf.withColumn(\"date_type\",to_date(current_timestamp())) \\\n  .show(truncate=False) \n\ndf.withColumn(\"ts\",to_timestamp(col(\"input_timestamp\"))) \\\n  .withColumn(\"datetype\",to_date(col(\"ts\"))) \\\n  .show(truncate=False)\n    \n#SQL TimestampType to DateType\nspark.sql(\"select to_date(current_timestamp) as date_type\")\n#SQL CAST TimestampType to DateType\nspark.sql(\"select date(to_timestamp('2019-06-24 12:01:19.000')) as date_type\")\n#SQL CAST timestamp string to DateType\nspark.sql(\"select date('2019-06-24 12:01:19.000') as date_type\")\n#SQL Timestamp String (default format) to DateType\nspark.sql(\"select to_date('2019-06-24 12:01:19.000') as date_type\")\n#SQL Custom Timeformat to DateType\nspark.sql(\"select to_date('06-24-2019 12:01:19.000','MM-dd-yyyy HH:mm:ss.SSSS') as date_type\")\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"ff454ace-29be-4943-88ec-dfbd947e4e3c","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["root\n |-- id: string (nullable = true)\n |-- input_timestamp: string (nullable = true)\n\n+---+-----------------------+----------+\n|id |input_timestamp        |date_type |\n+---+-----------------------+----------+\n|1  |2019-06-24 12:01:19.000|2019-06-24|\n+---+-----------------------+----------+\n\n+---+-----------------------+----------+\n|id |input_timestamp        |date_type |\n+---+-----------------------+----------+\n|1  |2019-06-24 12:01:19.000|2019-06-24|\n+---+-----------------------+----------+\n\n+----------------------------------------------------------+\n|to_date(06-24-2019 12:01:19.000, MM-dd-yyyy HH:mm:ss.SSSS)|\n+----------------------------------------------------------+\n|                                                2019-06-24|\n+----------------------------------------------------------+\n\n+---+-----------------------+----------+\n|id |input_timestamp        |date_type |\n+---+-----------------------+----------+\n|1  |2019-06-24 12:01:19.000|2019-06-24|\n+---+-----------------------+----------+\n\n+---+-----------------------+----------+\n|id |input_timestamp        |date_type |\n+---+-----------------------+----------+\n|1  |2019-06-24 12:01:19.000|2023-06-21|\n+---+-----------------------+----------+\n\n+---+-----------------------+-------------------+----------+\n|id |input_timestamp        |ts                 |datetype  |\n+---+-----------------------+-------------------+----------+\n|1  |2019-06-24 12:01:19.000|2019-06-24 12:01:19|2019-06-24|\n+---+-----------------------+-------------------+----------+\n\nOut[1]: DataFrame[date_type: date]"]}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"pyspark-timestamp-date.py","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{}}},"nbformat":4,"nbformat_minor":0}
