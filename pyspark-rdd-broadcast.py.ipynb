{"cells":[{"cell_type":"code","source":["import pyspark\nfrom pyspark.sql import SparkSession\n\nspark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()\n\nstates = {\"NY\":\"New York\", \"CA\":\"California\", \"FL\":\"Florida\"}\nbroadcastStates = spark.sparkContext.broadcast(states)\n\ndata = [(\"James\",\"Smith\",\"USA\",\"CA\"),\n    (\"Michael\",\"Rose\",\"USA\",\"NY\"),\n    (\"Robert\",\"Williams\",\"USA\",\"CA\"),\n    (\"Maria\",\"Jones\",\"USA\",\"FL\")\n  ]\n\nrdd = spark.sparkContext.parallelize(data)\n\ndef state_convert(code):\n    return broadcastStates.value[code]\n\nresult = rdd.map(lambda x: (x[0],x[1],x[2],state_convert(x[3]))).collect()\nprint(result)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"9b12e751-2ac4-48c9-83dd-f9f3a65fe59e","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["[('James', 'Smith', 'USA', 'California'), ('Michael', 'Rose', 'USA', 'New York'), ('Robert', 'Williams', 'USA', 'California'), ('Maria', 'Jones', 'USA', 'Florida')]\n"]}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"pyspark-rdd-broadcast.py","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{}}},"nbformat":4,"nbformat_minor":0}
