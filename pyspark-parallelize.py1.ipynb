{"cells":[{"cell_type":"code","source":["import pyspark\nfrom pyspark.sql import SparkSession\n\nspark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()\nrdd=spark.sparkContext.parallelize([1,2,3,4,5])\n\nrddCollect = rdd.collect()\nprint(\"Number of Partitions: \"+str(rdd.getNumPartitions()))\nprint(\"Action: First element: \"+str(rdd.first()))\nprint(rddCollect)\n\nemptyRDD = spark.sparkContext.emptyRDD()\nemptyRDD2 = rdd=spark.sparkContext.parallelize([])\n\nprint(\"\"+str(emptyRDD2.isEmpty()))"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"1c6baca7-c365-4b14-84a4-a886af94b162","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["Number of Partitions: 8\nAction: First element: 1\n[1, 2, 3, 4, 5]\nTrue\n"]}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"pyspark-parallelize.py1","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{}}},"nbformat":4,"nbformat_minor":0}
